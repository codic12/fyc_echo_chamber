let articles = [
  { id: 1, title: "Navigating the Echo Chambers: Society’s Sensitivity and AI’s Role in Reinforcing It", content: "We live in a time of unprecedented access to information, but also unprecedented fragmentation of perspectives. The internet and social media have enabled us to connect with people who share our views, interests, and identities, but also to isolate ourselves from those who disagree with us, challenge us, or offend us. This phenomenon, known as the echo chamber effect, has been amplified by the rise of artificial intelligence (AI) models that filter, rank, and recommend content based on our preferences, behaviors, and biases. These models, often hidden behind opaque algorithms, can influence what we see, hear, and think, without us being aware of their impact or their limitations. In this article, we will explore the themes of societal sensitivity, the challenge of handling opposing viewpoints, and the growing influence of AI models in shaping our information bubbles. We will also discuss some possible strategies to cope with these challenges, such as seeking diverse sources, engaging in constructive dialogue, and developing critical thinking skills. Our goal is to help you navigate the echo chambers and become a more informed, open-minded, and responsible citizen in the digital age.", tags: ["tech", "AI", "echo chambers"]},
  { id: 2, title: "Facebook and the echo chamber: scientists examine how social media affects political views", content: "One of the major concerns with social media is that it can create echo chambers: by surrounding ourselves with people and content that share our points of view, we can become increasingly entrenched in those opinions. Some have argued that this effect is responsible for the increasing political polarization of the United States. But does social media really deserve all of the blame? Research on this topic has been difficult since social media companies do not grant scientists access to their proprietary information. However, a team of 17 independent researchers from 12 universities was recently given unprecedented access to Facebook data, allowing them to conduct a series of studies on how social media shapes our views. A special investigator was also involved to ensure that corporate interests did not bias the scientists’ reports.  One of these studies focused on social media echo chambers. The researchers wanted to answer two questions: first, how biased are users’ Facebook feeds, and second, does this bias affect political views? To answer the first question, they analyzed 2020 data for all adult Americans with active Facebook accounts, finding that the majority of content that people see on the platform comes from “like-minded sources” (i.e., sources that share the user’s political leanings). These data confirm that social media feeds often act as echo chambers. To answer the second question, the researchers conducted a study of 23,377 consenting Facebook users, reducing the amount of like-minded content served to these users by one third over a period of three months. The participants completed surveys before and after the experiment, allowing the researchers to assess the impact of a less biased social media feed on political opinions. They found that the intervention had no effect on the users’ responses. Reducing polarization and bridging America’s political divide will require more than just a better social media algorithm.", tags: ["tech", "AI", "echo chambers"]},
  { id: 3, title: "How AI Fuels the Spread of Misinformation: The Role of Group Polarization and Confirmation Bias", content: "As social media becomes increasingly central to how we interact with information, it’s important to understand how AI based algorithms  and our psychology can influence what we see, share, and believe. Understanding the role of AI algorithms and how they work is critical to avoid the harmful side of social media.   Algorithms are not neutral, and their influence can have unintended consequences.  This has several implications when it comes to the spread of misinformation. First, it means that users are more likely to see stories confirming their beliefs and opinions, a phenomenon known as confirmation bias. Second, users are more likely to be exposed to extreme or sensationalized content, which can fuel group polarization and make it more challenging to separate fact from fiction.", tags: ["tech", "AI", "echo chambers"] },
  { id: 4, title: "Breaking the Echo: how AI shapes our digital echo chambers", content: "In our day-to-day digital experiences on social media, websites, and other platforms, machine learning plays a prominent role. One of its most notable applications is the recommendation algorithm, which significantly shapes our interaction with online content. Access to information today is often based on our ‘last click’, regardless of the device used. As we immerse ourselves in a world where information is increasingly tailored to our likes and dislikes, we find ourselves questioning whether technology, particularly artificial intelligence (or AI), is fueling or challenging the existence of echo chambers. Echo chambers, in the digital context, are environments where individuals primarily encounter beliefs or opinions that align with their own. This leads to existing views being reinforced, while alternative ideas are underrepresented. These echo chambers gain prominence in the era of machine learning and AI, technologies known for increasingly personalizing digital experiences to match individual preferences. While this personalization enhances user engagement, it can also lead to misinformation and skewed perceptions of reality.", tags: ["economy", "AI"], sentiment: "negative", tags: ["tech", "AI", "echo chambers"]},
  { id: 5, title: "The echo chamber effect: How algorithms shape our worldview", content: "Imagine a world where your beliefs and opinions are endlessly reinforced, where your perspective is never challenged, and alternative viewpoints are virtually non-existent.   In the media world, we call this the echo chamber.   This digital bubble, driven by algorithms and personalisation, reinforces our existing viewpoints and filters through the lenses of confirmation bias. And it is not just a matter of personal choice; it has profound implications for how we perceive the world and engage in online discourse. Confirmation bias, deeply ingrained in human psychology, is the inclination to seek, interpret, and remember information that aligns with our existing beliefs. It's more like our brain's default setting, and it's what makes social media platforms so addictive. Simply put, today’s platforms thrive by delivering content that reinforces our preconceived notions, keeping us engaged and generating revenue off of our views and engagement.",tags: ["tech", "AI", "echo chambers"] },
  {id: 6, title: "Echo Chamber Effect: How AI is Quietly Redefining Human Interaction", content: "In conclusion, while AI and personalization algorithms have revolutionized the way we interact with technology, they come with hidden dangers, particularly in how they affect our human connections. The echo chamber effect, amplified by AI, limits our exposure to diverse viewpoints, reinforcing our existing beliefs and isolating us from meaningful conversations and relationships. The 2020 U.S. Presidential election is a powerful example of how algorithms can shape public opinion, deepen political divides, and create social bubbles that are difficult to break free from. However, the very same technology that poses challenges to human connections can also be a tool for positive change — if we use it mindfully. By being aware of how AI affects our interactions, we can take steps to build more genuine relationships. Simple actions like practicing authenticity, meeting new people, and actively listening can go a long way in fostering real-world connections. We must also be cautious about how much time we spend consuming algorithm-curated content and instead, focus on activities that enhance our awareness and engage our minds in more meaningful ways.", tags: ["tech", "AI", "echo chambers"]},
  {id: 7, title: "The echo chamber effect on social media", content: "We explore the key differences between the main social media platforms and how they are likely to influence information spreading and the formation of echo chambers. To assess the different dynamics, we perform a comparative analysis on more than 100 million pieces of content concerning controversial topics (e.g., gun control, vaccination, abortion) from Gab, Facebook, Reddit, and Twitter. The analysis focuses on two main dimensions: 1) homophily in the interaction networks and 2) bias in the information diffusion toward like-minded peers. Our results show that the aggregation in homophilic clusters of users dominates online dynamics. However, a direct comparison of news consumption on Facebook and Reddit shows higher segregation on Facebook.", tags: ["tech", "AI", "echo chambers"]},
  {id: 8, title: "Social Media Echo Chambers: Why They Matter, How They Shape Us, and the Business Behind Them", content: "In today’s world, social media has a big impact on us, and I’m always amazed by how powerful it is. Yet, with this power, there’s a hidden trap many of us unknowingly fall into that impacts our perspectives more than we realize: echo chambers – a concept that isn’t new but has been magnified in the digital age.    Echo Chambers   So, what exactly is an echo chamber? Think of it as a room where the only voices you hear are echoes of your own. On social media, it means being surrounded primarily by opinions and views similar to yours. Every time you like, share, or engage with content, you are unknowingly signaling to the social media platform’s algorithm your preferences.   Echo chambers aren’t just a product of the digital age. Throughout history, people have naturally gravitated toward information that confirms their existing beliefs. In earlier times, newspapers, radio, and television played pivotal roles in this. People would often select newspapers that reflected their political views or tune into TV shows that mirrored their personal beliefs. While the technology has evolved, the intrinsic human desire for validation remains a constant. What’s shifted is the speed, scale, and precision with which you’re served these views. And how much easier it is to spread misinformation and disinformation rapidly in social media. ", tags: ["tech", "AI", "echo chambers"]},
  {id: 9, title: "Measuring magnetism: how social media creates echo chambers", content: "Social networks are often accused of encouraging polarisation and widening ideological divisions, but this effect has been rarely studied in detail. Now a study in Proceedings of the National Academy of Science shows how different platforms foster different levels of segregation in online communities, depending of their feed algorithms and their social networking features1. The researchers, led by Walter Quattrociocchi from Università La Sapienza in Rome, analysed more than a hundred million pieces of content — posts, as well as interactions such as likes, comments and re-posts — on controversial topics such as abortion, vaccinations, gun rights, and US presidential elections. The content came from four social media platforms: Facebook, Twitter, Reddit (one of the world’s most popular websites), and Gab, similar to Twitter and popular among right-wing extremists.", tags: ["tech", "AI", "echo chambers"]},
];

let userPreferences = { tags: ["tech", "AI", "echo chambers"], sentiment: "negative", feedback: [] };

async function generateEmbeddings(articles) {
  const model = await use.load();
  const embeddings = await model.embed(articles.map((article) => article.title));
  return embeddings;
}

async function calculateSimilarity(userContent, embeddings) {
  const model = await use.load();
  const userEmbedding = await model.embed([userContent]);
  const similarities = [];

  embeddings.unstack().forEach((embedding, i) => {
    const similarity = tf.losses.cosineDistance(
      userEmbedding.squeeze(),
      embedding,
      0
    ).arraySync();
    similarities.push(1 - similarity); // Convert distance to similarity
  });

  return similarities;
}

async function renderContent() {
  const mainContent = document.getElementById("main-content");
  const sideContent = document.getElementById("side-content");

  // Generate embeddings
  const embeddings = await generateEmbeddings(articles);

  // User content as a placeholder for preferences
  const userContent = "AI is transforming industries.";
  const similarities = await calculateSimilarity(userContent, embeddings);

  // Separate articles into echo chamber and diverse perspectives
  const echoChamberArticles = [];
  const diverseArticles = [];
  similarities.forEach((similarity, i) => {
    if (similarity > 0.3 || JSON.stringify(articles[i].tags) == JSON.stringify(userPreferences['tags'])) {
      echoChamberArticles.push(articles[i]);
    } else {
      diverseArticles.push(articles[i]);
    }
  });

  // Render articles as clickable titles
  mainContent.innerHTML = echoChamberArticles
    .map(
      (article) =>
        `<div><span class="article-title" onclick="showArticle(${article.id})">${article.title}</span></div>`
    )
    .join("");

  sideContent.innerHTML = diverseArticles
    .map(
      (article) =>
        `<div><span class="article-title" onclick="showArticle(${article.id})">${article.title}</span></div>`
    )
    .join("");
}

function showArticle(id) {
  const article = articles.find((a) => a.id === id);

  if (article) {
    document.body.innerHTML = `
      <div>
        <h1>${article.title}</h1>
        <p>${article.content}</p>
        <button onclick="feedback(${id}, 'helpful')">Helpful</button>
        <button onclick="feedback(${id}, 'unhelpful')">Unhelpful</button>
        <button onclick="location.reload()">Back</button>
      </div>
    `;
  }
}

function feedback(id, type) {
  const article = articles.find((a) => a.id === id);

  if (article) {
    if (type === "helpful") {
      userPreferences.feedback.push({ id: article.id, helpful: true });
    } else {
      userPreferences.feedback.push({ id: article.id, helpful: false });
    }
    alert(`${type === "helpful" ? "Marked Helpful" : "Marked Unhelpful"}!`);
  }

  location.reload(); // Reload to refresh content
}

// Update embeddings based on feedback
async function adaptModel() {
  const embeddings = await generateEmbeddings(articles);
  userPreferences.feedback.forEach((feedback) => {
    const index = articles.findIndex((a) => a.id === feedback.id);
    if (index !== -1) {
      const weight = feedback.helpful ? 1.1 : 0.9; // Increase or decrease similarity
      embeddings.arraySync()[index] = embeddings.arraySync()[index].map((value) => value * weight);
    }
  });
}

// Start rendering content
renderContent();
